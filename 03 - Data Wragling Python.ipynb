{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daed1198",
   "metadata": {},
   "source": [
    "## Membaca file dengan menggunakan pandas\n",
    "Sebagai salah satu library untuk melakukan proses awal dari analisis data, pandas juga memiliki kemampuan untuk membaca berbagai macam jenis file. Format yang bisa dibaca oleh pandas ada berbagai macam, antara lain .txt, .csv, .tsv, dan lainnya. Pandas tidak hanya bisa membaca file saja, namun juga bisa merubah data dari file menjadi bentuk dataframe yang akhirnya nanti bisa diakses, diagregasi dan diolah. Coba praktikan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea069e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0             1    Male   19                  15                      39\n",
      "1             2    Male   21                  15                      81\n",
      "2             3  Female   20                  16                       6\n",
      "3             4  Female   23                  16                      77\n",
      "4             5  Female   31                  17                      40\n",
      "..          ...     ...  ...                 ...                     ...\n",
      "195         196  Female   35                 120                      79\n",
      "196         197  Female   45                 126                      28\n",
      "197         198    Male   32                 126                      74\n",
      "198         199    Male   32                 137                      18\n",
      "199         200    Male   30                 137                      83\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0193bc1",
   "metadata": {},
   "source": [
    "## Membaca file dengan menggunakan head()\n",
    "Pada suatu kasus, data yang kita baca cukup banyak atau loading yang lama. Untuk memastikan data kita terbaca dengan baik dan bisa menampilkan data sebagian untuk ditampilkan secara benar, kita bisa memakai fungsi head(). Bisa dituliskan kode di bawah ini untuk prakteknya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05be7189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male   19                  15                      39\n",
      "1           2    Male   21                  15                      81\n",
      "2           3  Female   20                  16                       6\n",
      "3           4  Female   23                  16                      77\n",
      "4           5  Female   31                  17                      40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5627dfb",
   "metadata": {},
   "source": [
    "## Melakukan akses data kolom\n",
    "Dalam suatu analisis data ada kalanya kita hanya butuh melakukan akses beberapa data saja dan tidak perlu harus menampilkan semua data. Pada pandas kita bisa melakukan akses dalam berbagai kebutuhan. Mulai dari hanya akses kolom tertentu ataupun baris tertentu. Pada sesi kali ini kita akan mencoba untuk melakukan akses beberapa kolom tertentu pada suatu dataset.\n",
    "\n",
    "Pertama yang harus dilakukan untuk melakukan akses kolom adalah mengetahui nama-nama kolom yang ada. Coba ketikkan kode di bawah ini untuk melihat nama kolom yang ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff502408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CustomerID', 'Genre', 'Age', 'Annual Income (k$)',\n",
      "       'Spending Score (1-100)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aded06b",
   "metadata": {},
   "source": [
    "**Note :** Pada dataset ini ada 5 kolom termasuk class, dimana 4 kolom  merupakan data numerik dan 1 kolom merupakan data string. Pada praktek selanjutnya kita akan mencoba mengakses data age. Untuk melakukannya coba tuliskan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70404be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      19\n",
      "1      21\n",
      "2      20\n",
      "3      23\n",
      "4      31\n",
      "       ..\n",
      "195    35\n",
      "196    45\n",
      "197    32\n",
      "198    32\n",
      "199    30\n",
      "Name: Age, Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebfd21",
   "metadata": {},
   "source": [
    "## Melakukan akses data melalui baris\n",
    "Selain melakukan akses data melalui kolom, dengan menggunakan pandas juga bisa melakukan akses dengan menggunakan baris. Berbeda dengan akses melalui kolom, fungsi untuk menampilkan data dari suatu baris adalah fungsi **.iloc[i]** dimana [i] menunjukan urutan baris yang akan ditampilkan yang dimana indexnya diawali dari 0. Coba ketikan code di bawah ini untuk mempermudah :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86df43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                     6\n",
      "Genre                     Female\n",
      "Age                           22\n",
      "Annual Income (k$)            17\n",
      "Spending Score (1-100)        76\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data.iloc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db47b5",
   "metadata": {},
   "source": [
    "## Menampilkan suatu data dari baris dan kolom tertentu\n",
    "Tidak hanya dengan menentukan dari kolom dan baris, dengan menggunakan pandas kita juga bisa memanggil suatu data dari suatu baris dan kolom tertentu dalam satu waktu. Perhatikan dan coba kode di bawah ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a1207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Cuplikan Dataset:\n",
      "   CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male   19                  15                      39\n",
      "1           2    Male   21                  15                      81\n",
      "2           3  Female   20                  16                       6\n",
      "3           4  Female   23                  16                      77\n",
      "4           5  Female   31                  17                      40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data[\"Age\"].iloc[1])\n",
    "\n",
    "print(\"Cuplikan Dataset:\")\n",
    "\n",
    "print(csv_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f2ae5",
   "metadata": {},
   "source": [
    "### Menampilkan data dalam range tertentu\n",
    "Setelah menampilkan suatu kelompok data, bagaimana jika ingin menampilkan data dari baris ke 5 sampai ke 20 dari suatu dataset? Untuk mengantisipasi hal tersebut, pandas juga bisa menampilkan data dalam range tertentu, baik range untuk baris saja, kolom saja, dan range untuk baris dan kolom.\n",
    "\n",
    "Akses range pada suatu kolom dan baris tertentu, untuk mencobanya silahkan ketikkan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757505fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menampilkan data ke 5 sampai kurang dari 10 :\n",
      "5    22\n",
      "6    35\n",
      "7    23\n",
      "8    64\n",
      "9    30\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(\"Menampilkan data ke 5 sampai kurang dari 10 :\")\n",
    "\n",
    "print(csv_data[\"Age\"].iloc[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a1fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menampilkan data ke 5 sampai kurang dari 10 dalam satu baris:\n",
      "   CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "5           6  Female   22                  17                      76\n",
      "6           7  Female   35                  18                       6\n",
      "7           8  Female   23                  18                      94\n",
      "8           9    Male   64                  19                       3\n",
      "9          10  Female   30                  19                      72\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan suatu range data tertentu pada suatu baris saja. Cobalah ketikan kode di bawah ini :\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(\"Menampilkan data ke 5 sampai kurang dari 10 dalam satu baris:\")\n",
    "\n",
    "print(csv_data.iloc[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd486c1a",
   "metadata": {},
   "source": [
    "### Menampilkan informasi statistik dengan Numpy\n",
    "Mengetahui informasi statistik pada suatu data sangat penting. Mulai dari distribusi data, **nilai max atau min, hingga standar deviasi** dari suatu dataset. Jika datanya berjumlah dibawah 10 mungkin masih dikerjakan secara manual. Namun, bayangkan jika datanya sudah mencapai ratusan bahkan ribuan. Tidak mungkin pastinya untuk dilakukan secara manual. Maka dari itu pentingnya fungsi **describe()** pada pandas. Fungsi describe() ini memungkinkan untuk mengetahui informasi statistik dari suatu dataset secara cepat. Coba untuk ketikkan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f95bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerID   Genre         Age  Annual Income (k$)  \\\n",
      "count   200.000000     200  200.000000          200.000000   \n",
      "unique         NaN       2         NaN                 NaN   \n",
      "top            NaN  Female         NaN                 NaN   \n",
      "freq           NaN     112         NaN                 NaN   \n",
      "mean    100.500000     NaN   38.850000           60.560000   \n",
      "std      57.879185     NaN   13.969007           26.264721   \n",
      "min       1.000000     NaN   18.000000           15.000000   \n",
      "25%      50.750000     NaN   28.750000           41.500000   \n",
      "50%     100.500000     NaN   36.000000           61.500000   \n",
      "75%     150.250000     NaN   49.000000           78.000000   \n",
      "max     200.000000     NaN   70.000000          137.000000   \n",
      "\n",
      "        Spending Score (1-100)  \n",
      "count               200.000000  \n",
      "unique                     NaN  \n",
      "top                        NaN  \n",
      "freq                       NaN  \n",
      "mean                 50.200000  \n",
      "std                  25.823522  \n",
      "min                   1.000000  \n",
      "25%                  34.750000  \n",
      "50%                  50.000000  \n",
      "75%                  73.000000  \n",
      "max                  99.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f408975",
   "metadata": {},
   "source": [
    "**Note :** Banyak nilai NaN yang tampil. Hal itu karena pada dataset ada format data string yang akhirnya memunculkan format NaN.\n",
    "\n",
    "Untuk meminimalisir hal tersebut dan memfilter hanya data numerical saja, digunakan  exclude=[\"O\"], dimana fungsi itu akan mengabaikan data yang non-numerical untuk diproses. Coba implementasikan code di bawah ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05358114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CustomerID         Age  Annual Income (k$)  Spending Score (1-100)\n",
      "count  200.000000  200.000000          200.000000              200.000000\n",
      "mean   100.500000   38.850000           60.560000               50.200000\n",
      "std     57.879185   13.969007           26.264721               25.823522\n",
      "min      1.000000   18.000000           15.000000                1.000000\n",
      "25%     50.750000   28.750000           41.500000               34.750000\n",
      "50%    100.500000   36.000000           61.500000               50.000000\n",
      "75%    150.250000   49.000000           78.000000               73.000000\n",
      "max    200.000000   70.000000          137.000000               99.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data.describe(exclude=[\"O\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5728f66",
   "metadata": {},
   "source": [
    "## Handling Missing Value\n",
    "Pada suatu dataset, ada kalanya data yang kita akan kita kelola tidak lengkap. Hal ini tentunya akan menyulitkan atau membuat hasil analisa tidak akurat. Penanggulangan akan data yang hilang ini biasa disebut Handling Missing Value. Penanganan dari nilai yang kosong ini banyak caranya. Sebagai seorang data science yang berhubungan dengan data yang real, solusi pertama yang benar-benar kita anjurkan untuk kasus seperti ini adalah melakukan trace kembali ke sumber data atau memerika ulang record. Terutama jika data itu berasal dari human record. Sangat disarankan untuk menelusuri kembali agar tidak terjadi kesalahan ketika sudah mencapai titik analisa. Selain solusi untuk melakukan penelusuran kembali ke sumberdata, pada ilmu data science juga ada beberapa metode yang bisa dijadikan solusi untuk menangani kasus ini.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb385b9",
   "metadata": {},
   "source": [
    "### Melakukan pengecekan untuk nilai NULL yang ada\n",
    "Dengan menggunakan fungsi pandas, kita tidak perlu melihat satu persatu baris data untuk mengetahui apakah ada nilai kosong atau NULL/NAN pada suatu dataset. Bayangkan jika kita memilki 1000 baris data. Apakah kita harus melihat semua baris data tersebut? Tentu saja tidak. Maka dari itu di pandas disediakan fungsi untuk mengecek apakah ada data yang kosong. Coba praktikkan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c845bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "\n",
    "print(csv_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491624c",
   "metadata": {},
   "source": [
    "**Note :** data yang digunakan merupakan data yang lengkap, maka dari itu output yang dihasilkan False. Coba Sekarang ganti dengan dataset yang memang terdapat data yang kosong. Coba ketikkan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34c951cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data_missingvalue.csv\")\n",
    "\n",
    "print(csv_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8349c6",
   "metadata": {},
   "source": [
    "### Solusi mengisi Missing Value\n",
    "Sebelum mengenal lebih banyak mengenai Solusi yang biasa ada pada kasus-kasus data science.\n",
    "\n",
    "Skema yang biasanya sering dalam pengelolaan data.\n",
    "\n",
    "    Cara Handling Missing Value :\n",
    "        1. Delete Data :\n",
    "            a. Deleting Rows\n",
    "            b. Pairwise Deletion\n",
    "            c. Delete Column\n",
    "        2. Imputation :\n",
    "            a. Time Series Problem :\n",
    "                - Data Without Trend --> Mean, Median, Mode, Random.\n",
    "                - Data With Trend and Without Seasonality --> Linear Interpolation\n",
    "                - Data With Trend and With Seasonality --> Seaseonal Suggestion + Interpolation\n",
    "            b. General Problem :\n",
    "                - Data Categorical --> Mak NA as Multiple Imputation and Logistic Regression\n",
    "                - Data Numerical and Continuous --> Mean, Median, Mode, Multiple Imputation and Linear Regression\n",
    "\n",
    "Dalam diagram diatas, perlu diketahui bahwa kasus kehilangan data bisa diatasi dengan berbagai cara. Bahkan, melakukan penghapusan data juga merupakan solusi yang bisa menjadi pilihan apabila jika dirasa mengisi nilai kosong akan memberikan pengaruh yang kurang bagus terhadap analisa, atau apabila pertimbangan data yang dihapus atau data yang hilang sedikit dan tidak memberikan terlalu banyak sumbangsih untuk analisa yang akan dilakukan. Penghapusan data bisa langsung pada baris data tersebut atau langsung satu kolom data. Pada solusi kedua yaitu menggunakan imputation (pengisian data yang kosong) bisa tergantung dari permasalahannya. Khusus untuk masalah yang berhubungan forecasting atau peramalan tergantung dari data yang ada (lebih lengkap bisa dilihat pada gambar). Khusus untuk general problem tergantung jenis datanya. Jika yang hilang data kategorikal atau bersifat string bisa menggunakna relasi antar kolom dengan Logistic Regression, jika numerical bisa menggunakan statistik sederhana dan linear regression. Pada sesi kali ini kita akan mencoba menangani data hilang dengan statistik sederhana, Mean dan Median.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b1f99",
   "metadata": {},
   "source": [
    "### Mengisi dengan Mean\n",
    "Salah satu metode yang bisa dikatakan sebagai solusi yang umum pada kasus general data science adalah mengisi data kosong dengan menggunakan mean dari masing-masing kolom. Pertama kita harus menentukan mean dari masing-masing kolom. Pada pandas terdapat fungsi mean() untuk menentukan nilai mean dari masing-masing kolom. Mean sendiri digunakan untuk data yang memiliki sedikit sifat outlier/noisy/anomali dalam sebaran datanya maupun isinya.  Coba ketikkan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192dc1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                100.500000\n",
      "Age                        38.939698\n",
      "Annual Income (k$)         61.005051\n",
      "Spending Score (1-100)     50.489899\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/1ktjrh812fb6t_ykc06y1ddc0000gn/T/ipykernel_60243/2028070134.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(csv_data.mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data_missingvalue.csv\")\n",
    "\n",
    "print(csv_data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07c7ca",
   "metadata": {},
   "source": [
    "Fungsi mean sendiri berfungsi untuk menampilkan  nilai mean (rata-rata) dari setiap kolom. \n",
    "Nilai inilah nanti yang akan mengisi nilai kosong dari dataset yang mengalami kasus missing value. Untuk mengisi nilai yang kosong menggunakan fungsi **fillna()**, coba ketikkan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84c0f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                100.500000\n",
      "Age                        38.939698\n",
      "Annual Income (k$)         61.005051\n",
      "Spending Score (1-100)     50.489899\n",
      "dtype: float64\n",
      "Dataset yang masih terdapat nilai kosong ! :\n",
      "   CustomerID   Genre   Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male  19.0                15.0                    39.0\n",
      "1           2    Male   NaN                15.0                    81.0\n",
      "2           3  Female  20.0                 NaN                     6.0\n",
      "3           4  Female  23.0                16.0                    77.0\n",
      "4           5  Female  31.0                17.0                     NaN\n",
      "5           6  Female  22.0                 NaN                    76.0\n",
      "6           7  Female  35.0                18.0                     6.0\n",
      "7           8  Female  23.0                18.0                    94.0\n",
      "8           9    Male  64.0                19.0                     NaN\n",
      "9          10  Female  30.0                19.0                    72.0\n",
      "Dataset yang sudah diproses Handling Missing Values dengan Mean :\n",
      "   CustomerID   Genre        Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male  19.000000           15.000000               39.000000\n",
      "1           2    Male  38.939698           15.000000               81.000000\n",
      "2           3  Female  20.000000           61.005051                6.000000\n",
      "3           4  Female  23.000000           16.000000               77.000000\n",
      "4           5  Female  31.000000           17.000000               50.489899\n",
      "5           6  Female  22.000000           61.005051               76.000000\n",
      "6           7  Female  35.000000           18.000000                6.000000\n",
      "7           8  Female  23.000000           18.000000               94.000000\n",
      "8           9    Male  64.000000           19.000000               50.489899\n",
      "9          10  Female  30.000000           19.000000               72.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/1ktjrh812fb6t_ykc06y1ddc0000gn/T/ipykernel_60243/3521058562.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(csv_data.mean())\n",
      "/var/folders/n0/1ktjrh812fb6t_ykc06y1ddc0000gn/T/ipykernel_60243/3521058562.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  csv_data=csv_data.fillna(csv_data.mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data_missingvalue.csv\")\n",
    "print(csv_data.mean())\n",
    "print(\"Dataset yang masih terdapat nilai kosong ! :\")\n",
    "print(csv_data.head(10))\n",
    "\n",
    "csv_data=csv_data.fillna(csv_data.mean())\n",
    "print(\"Dataset yang sudah diproses Handling Missing Values dengan Mean :\")\n",
    "print(csv_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf54e0c",
   "metadata": {},
   "source": [
    "### Mengisi dengan Median\n",
    "Berbeda dengan mean pada sesi sebelumnya, median digunakan untuk data-data yang memiliki sifat outlier yang kuat. Kenapa median dipilih? Median merupakan nilai tengah yang artinya bukan hasil dari perhitungan yang melibatkan data outlier. Pada beberapa kasus, data outlier dianggap mengganggu dan sering dianggap noisy karena bisa mempengaruhi distribusi kelas dan mengganggu analisa pada klasterisasi (clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e0a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID                100.5\n",
      "Age                        36.0\n",
      "Annual Income (k$)         62.0\n",
      "Spending Score (1-100)     50.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/1ktjrh812fb6t_ykc06y1ddc0000gn/T/ipykernel_60243/2473665212.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(csv_data.median())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data_missingvalue.csv\")\n",
    "\n",
    "print(csv_data.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8c8d7",
   "metadata": {},
   "source": [
    "Sama dengan sesi sebelumnya dengan **mean()**, gunakan kode di bawah ini untuk mengisi nilai yang kosong menggunakan fungsi **fillna()** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54171c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yang masih terdapat nilai kosong ! :\n",
      "   CustomerID   Genre   Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male  19.0                15.0                    39.0\n",
      "1           2    Male   NaN                15.0                    81.0\n",
      "2           3  Female  20.0                 NaN                     6.0\n",
      "3           4  Female  23.0                16.0                    77.0\n",
      "4           5  Female  31.0                17.0                     NaN\n",
      "5           6  Female  22.0                 NaN                    76.0\n",
      "6           7  Female  35.0                18.0                     6.0\n",
      "7           8  Female  23.0                18.0                    94.0\n",
      "8           9    Male  64.0                19.0                     NaN\n",
      "9          10  Female  30.0                19.0                    72.0\n",
      "Dataset yang sudah diproses Handling Missing Values dengan Median :\n",
      "   CustomerID   Genre   Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male  19.0                15.0                    39.0\n",
      "1           2    Male  36.0                15.0                    81.0\n",
      "2           3  Female  20.0                62.0                     6.0\n",
      "3           4  Female  23.0                16.0                    77.0\n",
      "4           5  Female  31.0                17.0                    50.0\n",
      "5           6  Female  22.0                62.0                    76.0\n",
      "6           7  Female  35.0                18.0                     6.0\n",
      "7           8  Female  23.0                18.0                    94.0\n",
      "8           9    Male  64.0                19.0                    50.0\n",
      "9          10  Female  30.0                19.0                    72.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/1ktjrh812fb6t_ykc06y1ddc0000gn/T/ipykernel_60243/3740656576.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  csv_data=csv_data.fillna(csv_data.median())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data_missingvalue.csv\")\n",
    "print(\"Dataset yang masih terdapat nilai kosong ! :\")\n",
    "print(csv_data.head(10))\n",
    "\n",
    "csv_data=csv_data.fillna(csv_data.median())\n",
    "print(\"Dataset yang sudah diproses Handling Missing Values dengan Median :\")\n",
    "print(csv_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf82d",
   "metadata": {},
   "source": [
    "### Normalisasi Data\n",
    "Terkadang pada beberapa kasus, 1 kolom dengan kolom yang lain memiliki skala yang berbeda. Seperti cuplikan gambar di bawah ini :\n",
    "\n",
    "No   Usia    Masa Kerja (Tahun)   Gaji\n",
    "\n",
    "1    50      30                   10000000\n",
    "\n",
    "2    30      10                   5000000\n",
    "\n",
    "Antara Usia dan Masa Kerja masih memiliki range yang sama dalam skala puluhan. Namun, jika kolom Usia dan Masa Kerja dibandingkan dengan Gaji memiliki range nilai yang berbeda, dimana Usia dan Masa Kerja memiliki range puluhan dan Gaji mempunyai range nilai jutaan. Memang terlihat sederhana, namun hal ini bisa menjadi masalah besar dalam contoh kasus klasterisasi atau klasifikasi. Masuk pada kasus K-means yang sudah pernah dibahas sebelumnya. **K-means** merupakan **algoritma klasterisasi (clustering)** yang menggunakan perhitungan jarak dalam prosesnya. Sekarang coba bayangkan :\n",
    "\n",
    "  sqrt( ( centroid - usia ) + ( centroid - masa kerja) + ( centroid - gaji) )\n",
    "                          \n",
    "         domain puluhan.             domain jutaan\n",
    "                          \n",
    " **Note :** sqrt = akar\n",
    "\n",
    "Jika tidak ada normalisasi, maka jelas perhitungan kmeans diatas akan tergantung pada Gaji. Kenapa? Karena gaji berdomain jutaan dan 2 kolom lainnya hanya berdomain puluhan. Berapapun usia dan masa kerja seseorang tidak akan berpengaruh terhadap penilaian suatu perusahaan. Perbedaan skala pada setiap kolom ini merupakan hal yang sangat wajar dan sering terjadi dan inilah pentingnya normalisasi. Normalisasi sangat penting, terutama untuk yang menggunakan perhitungan jarak dengan menggunakan metode apapun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139317a",
   "metadata": {},
   "source": [
    "## Metode Normalisasi\n",
    "Ada berbagai macam metode normalisasi, seperti MinMax, Zscore, Decimal Scaling, Sigmoid, dan Softmax. Pemakaiannya tergantung pada kebutuhan dari dataset dan jenis analisa yang dilakukan.\n",
    "\n",
    "### MinMax\n",
    "Metode Min-Max merupakan metode yang cukup bisa dibayangkan karena termasuk metode normalisasi yang bersifat linier dengan data aslinya. Namun, metode ini bisa menyebabkan out of bound pada beberapa kasus.\n",
    "\n",
    "    Min - Max Formula :\n",
    "    New_data = (((current_data - min) * ( new_max - new_min)) / ( Max - Min)) + new_min\n",
    "    \n",
    "    dimana :\n",
    "    New_data = data baru hasil normalisasi\n",
    "    current_data = data terkini yang akan di normalisasi\n",
    "    min = nilai terkecil dari suatu kolom baris data\n",
    "    max = nilai terbesar dari suatu kolom baris data\n",
    "    new_min = batas nilai terkecil dari normalisasi\n",
    "    new_max = batas nilai terbesar dari normalisasi\n",
    "    \n",
    "\n",
    "\n",
    "Kenapa bisa terjadi out of bound? Out of Bound terjadi apabila ada data baru masuk, dimana data tersebut melebihi nilai maksimal atau nilai minimal dari data yang sudah ada. Secara otomatis, perhitungan yang berlaku pada data yang sudah diperoleh tadi harus diulangi lagi semuanya dengan data baru yang masuk atau data baru yang mempunyai nilai maksimal/minimum yang melebihi tadi tidak bisa diproses. Karena kekurangan inilah MinMax tidak cocok untuk analisa real time / evolving system. Dimungkinkan dalam kasus-kasus terjadi kasus out of bound pada MinMax.\n",
    "\n",
    "MinMax sangat dianjurkan untuk kasus-kasus berbasis time frame analisis dan forecasting. Perhitungan dari metode ini cukup mengurangi data yang asli dengan nilai minimal dari fitur tersebut, kemudian hasil tersebut dikalikan dari hasil pengurangan nilai maximal yang baru dengan nilai minimal yang baru dan kemudian dibagi dengan nilai max dan min data di setiap fitur terakhir ditambah dengan nilai min yang baru.\n",
    "\n",
    "### Z-Score\n",
    "Zscore adalah metode yang sering digunakan dalam berbagai penelitian berbasis data mining atau data science. Z-score merupakan metode normalisasi yang berdasarkan mean (nilai rata-rata) dan standard deviation (deviasi standar) dari data. Kenapa Z-Score sangat populer? Selain tidak banyak variabel yang diset dalam perhitungannya. Z-Score sangat dinamis dalam melakukan perhitungan normalisasi. Kelemahan dari Z-Score adalah prosesnya akan terulang lagi jika ada data baru yang masuk. Selain itu elemen yang dibutuhkan untuk perhitungan Z-Score juga membutuhkan proses yang cukup lama baik standar deviation ataupun rata-rata dari setiap kolom.\n",
    "\n",
    "    Z-Score Formula :\n",
    "    New_data = ( Current_data - mean of columns) / standar_deviations of columns\n",
    "    \n",
    "    dimana :\n",
    "    New_data = data baru hasil normalisasi\n",
    "    Current_data = data terkini yang akan di normalisasi\n",
    "    mean of columns = rata-rata dari setiap kolom\n",
    "    standar_deviations of columns = standar deviasi dari setiap kolom\n",
    "\n",
    "\n",
    "### Decimal Scaling\n",
    "\n",
    "    Decimal_Scaling Formula :\n",
    "    New_data = current_data / 10**n\n",
    "    \n",
    "    dimana :\n",
    "    New_data = data baru hasil normalisasi\n",
    "    current_data = data terkini yang akan di normalisasi\n",
    "    n = pangkat untuk pembagi\n",
    "\n",
    "\n",
    "### Softmax\n",
    "Softmax merupakan metode normalisasi pengembangan transformasi secara linier. Output range-nya adalah 0-1. Metode ini sangat berguna pada saat data yang ada melibatkan data outlier.\n",
    "\n",
    "    Softmax Formula :\n",
    "    New_data = 1 / (1 + e**(-transfdata))\n",
    "    \n",
    "    dimana :\n",
    "    New_data = data baru hasil normalisasi\n",
    "    transfdata = (current_data - mean) / (x * (standar_deviasi/(2*3.14)))\n",
    "    current_data = data terkini yang akan di normalisasi\n",
    "    x = respon linier pada standar deviasi ( range 0 - 1 )\n",
    "    e = 2.718281828\n",
    "\n",
    "\n",
    "### Sigmoid\n",
    "Sigmoidal merupakan metode normalization melakukan normalisasi data secara nonlinier ke dalam range -1 s/d 1 dengan menggunakan fungsi sigmoid. Metode ini sangat berguna pada saat data yang ada melibatkan data outlier. Data outlier adalah data yang keluar jauh dari jangkauan data lainnya\n",
    "\n",
    "    Sigmoid Formula :\n",
    "    New_data = (1 - e**(-x)) / (1 + e**(-x))\n",
    "    \n",
    "    dimana : \n",
    "    New_data = data baru hasil normalisasi\n",
    "    e = 2.718281828 ( eksponensial)\n",
    "    x = ( current_data - mean of columns) / standar_deviation of columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36686e9e",
   "metadata": {},
   "source": [
    "## Praktek Normalisasi menggunakan Scikit Learn pada Python\n",
    "**Scikit Learn** merupakan library pada python yang digunakan untuk machine learning dan data science. Salah satu library yang selalu menjadi favorit dan komunitasnya sangat kuat. Scikit-learn sendiri tidak hanya untuk analytics saja, namun juga untuk **pre-processing, feature selection, dan proses analysis lainnya.** Melanjutkan dari sesi normalisasi data, mari kita praktekan kode di bawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326d664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "csv_data = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/shopping_data.csv\")\n",
    "array = csv_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e905621",
   "metadata": {},
   "source": [
    "**X** merupakan matriks yang berisi fitur dataset yang akan digunakan dalam **machine learning, baik untuk regresi, klasifikasi, pengklusteran, atau normalisasi**\n",
    "\n",
    "Pada kasus kita, X berisi fitur-fitur yang digunakan untuk dinormalisasi dengan **teknik min-max scaler**\n",
    "\n",
    "Ketik lanjutan dari kode di atas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "721706d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Male', 19, 15, 39],\n",
       "       [2, 'Male', 21, 15, 81],\n",
       "       [3, 'Female', 20, 16, 6],\n",
       "       [4, 'Female', 23, 16, 77],\n",
       "       [5, 'Female', 31, 17, 40],\n",
       "       [6, 'Female', 22, 17, 76],\n",
       "       [7, 'Female', 35, 18, 6],\n",
       "       [8, 'Female', 23, 18, 94],\n",
       "       [9, 'Male', 64, 19, 3],\n",
       "       [10, 'Female', 30, 19, 72],\n",
       "       [11, 'Male', 67, 19, 14],\n",
       "       [12, 'Female', 35, 19, 99],\n",
       "       [13, 'Female', 58, 20, 15],\n",
       "       [14, 'Female', 24, 20, 77],\n",
       "       [15, 'Male', 37, 20, 13],\n",
       "       [16, 'Male', 22, 20, 79],\n",
       "       [17, 'Female', 35, 21, 35],\n",
       "       [18, 'Male', 20, 21, 66],\n",
       "       [19, 'Male', 52, 23, 29],\n",
       "       [20, 'Female', 35, 23, 98],\n",
       "       [21, 'Male', 35, 24, 35],\n",
       "       [22, 'Male', 25, 24, 73],\n",
       "       [23, 'Female', 46, 25, 5],\n",
       "       [24, 'Male', 31, 25, 73],\n",
       "       [25, 'Female', 54, 28, 14],\n",
       "       [26, 'Male', 29, 28, 82],\n",
       "       [27, 'Female', 45, 28, 32],\n",
       "       [28, 'Male', 35, 28, 61],\n",
       "       [29, 'Female', 40, 29, 31],\n",
       "       [30, 'Female', 23, 29, 87],\n",
       "       [31, 'Male', 60, 30, 4],\n",
       "       [32, 'Female', 21, 30, 73],\n",
       "       [33, 'Male', 53, 33, 4],\n",
       "       [34, 'Male', 18, 33, 92],\n",
       "       [35, 'Female', 49, 33, 14],\n",
       "       [36, 'Female', 21, 33, 81],\n",
       "       [37, 'Female', 42, 34, 17],\n",
       "       [38, 'Female', 30, 34, 73],\n",
       "       [39, 'Female', 36, 37, 26],\n",
       "       [40, 'Female', 20, 37, 75],\n",
       "       [41, 'Female', 65, 38, 35],\n",
       "       [42, 'Male', 24, 38, 92],\n",
       "       [43, 'Male', 48, 39, 36],\n",
       "       [44, 'Female', 31, 39, 61],\n",
       "       [45, 'Female', 49, 39, 28],\n",
       "       [46, 'Female', 24, 39, 65],\n",
       "       [47, 'Female', 50, 40, 55],\n",
       "       [48, 'Female', 27, 40, 47],\n",
       "       [49, 'Female', 29, 40, 42],\n",
       "       [50, 'Female', 31, 40, 42],\n",
       "       [51, 'Female', 49, 42, 52],\n",
       "       [52, 'Male', 33, 42, 60],\n",
       "       [53, 'Female', 31, 43, 54],\n",
       "       [54, 'Male', 59, 43, 60],\n",
       "       [55, 'Female', 50, 43, 45],\n",
       "       [56, 'Male', 47, 43, 41],\n",
       "       [57, 'Female', 51, 44, 50],\n",
       "       [58, 'Male', 69, 44, 46],\n",
       "       [59, 'Female', 27, 46, 51],\n",
       "       [60, 'Male', 53, 46, 46],\n",
       "       [61, 'Male', 70, 46, 56],\n",
       "       [62, 'Male', 19, 46, 55],\n",
       "       [63, 'Female', 67, 47, 52],\n",
       "       [64, 'Female', 54, 47, 59],\n",
       "       [65, 'Male', 63, 48, 51],\n",
       "       [66, 'Male', 18, 48, 59],\n",
       "       [67, 'Female', 43, 48, 50],\n",
       "       [68, 'Female', 68, 48, 48],\n",
       "       [69, 'Male', 19, 48, 59],\n",
       "       [70, 'Female', 32, 48, 47],\n",
       "       [71, 'Male', 70, 49, 55],\n",
       "       [72, 'Female', 47, 49, 42],\n",
       "       [73, 'Female', 60, 50, 49],\n",
       "       [74, 'Female', 60, 50, 56],\n",
       "       [75, 'Male', 59, 54, 47],\n",
       "       [76, 'Male', 26, 54, 54],\n",
       "       [77, 'Female', 45, 54, 53],\n",
       "       [78, 'Male', 40, 54, 48],\n",
       "       [79, 'Female', 23, 54, 52],\n",
       "       [80, 'Female', 49, 54, 42],\n",
       "       [81, 'Male', 57, 54, 51],\n",
       "       [82, 'Male', 38, 54, 55],\n",
       "       [83, 'Male', 67, 54, 41],\n",
       "       [84, 'Female', 46, 54, 44],\n",
       "       [85, 'Female', 21, 54, 57],\n",
       "       [86, 'Male', 48, 54, 46],\n",
       "       [87, 'Female', 55, 57, 58],\n",
       "       [88, 'Female', 22, 57, 55],\n",
       "       [89, 'Female', 34, 58, 60],\n",
       "       [90, 'Female', 50, 58, 46],\n",
       "       [91, 'Female', 68, 59, 55],\n",
       "       [92, 'Male', 18, 59, 41],\n",
       "       [93, 'Male', 48, 60, 49],\n",
       "       [94, 'Female', 40, 60, 40],\n",
       "       [95, 'Female', 32, 60, 42],\n",
       "       [96, 'Male', 24, 60, 52],\n",
       "       [97, 'Female', 47, 60, 47],\n",
       "       [98, 'Female', 27, 60, 50],\n",
       "       [99, 'Male', 48, 61, 42],\n",
       "       [100, 'Male', 20, 61, 49],\n",
       "       [101, 'Female', 23, 62, 41],\n",
       "       [102, 'Female', 49, 62, 48],\n",
       "       [103, 'Male', 67, 62, 59],\n",
       "       [104, 'Male', 26, 62, 55],\n",
       "       [105, 'Male', 49, 62, 56],\n",
       "       [106, 'Female', 21, 62, 42],\n",
       "       [107, 'Female', 66, 63, 50],\n",
       "       [108, 'Male', 54, 63, 46],\n",
       "       [109, 'Male', 68, 63, 43],\n",
       "       [110, 'Male', 66, 63, 48],\n",
       "       [111, 'Male', 65, 63, 52],\n",
       "       [112, 'Female', 19, 63, 54],\n",
       "       [113, 'Female', 38, 64, 42],\n",
       "       [114, 'Male', 19, 64, 46],\n",
       "       [115, 'Female', 18, 65, 48],\n",
       "       [116, 'Female', 19, 65, 50],\n",
       "       [117, 'Female', 63, 65, 43],\n",
       "       [118, 'Female', 49, 65, 59],\n",
       "       [119, 'Female', 51, 67, 43],\n",
       "       [120, 'Female', 50, 67, 57],\n",
       "       [121, 'Male', 27, 67, 56],\n",
       "       [122, 'Female', 38, 67, 40],\n",
       "       [123, 'Female', 40, 69, 58],\n",
       "       [124, 'Male', 39, 69, 91],\n",
       "       [125, 'Female', 23, 70, 29],\n",
       "       [126, 'Female', 31, 70, 77],\n",
       "       [127, 'Male', 43, 71, 35],\n",
       "       [128, 'Male', 40, 71, 95],\n",
       "       [129, 'Male', 59, 71, 11],\n",
       "       [130, 'Male', 38, 71, 75],\n",
       "       [131, 'Male', 47, 71, 9],\n",
       "       [132, 'Male', 39, 71, 75],\n",
       "       [133, 'Female', 25, 72, 34],\n",
       "       [134, 'Female', 31, 72, 71],\n",
       "       [135, 'Male', 20, 73, 5],\n",
       "       [136, 'Female', 29, 73, 88],\n",
       "       [137, 'Female', 44, 73, 7],\n",
       "       [138, 'Male', 32, 73, 73],\n",
       "       [139, 'Male', 19, 74, 10],\n",
       "       [140, 'Female', 35, 74, 72],\n",
       "       [141, 'Female', 57, 75, 5],\n",
       "       [142, 'Male', 32, 75, 93],\n",
       "       [143, 'Female', 28, 76, 40],\n",
       "       [144, 'Female', 32, 76, 87],\n",
       "       [145, 'Male', 25, 77, 12],\n",
       "       [146, 'Male', 28, 77, 97],\n",
       "       [147, 'Male', 48, 77, 36],\n",
       "       [148, 'Female', 32, 77, 74],\n",
       "       [149, 'Female', 34, 78, 22],\n",
       "       [150, 'Male', 34, 78, 90],\n",
       "       [151, 'Male', 43, 78, 17],\n",
       "       [152, 'Male', 39, 78, 88],\n",
       "       [153, 'Female', 44, 78, 20],\n",
       "       [154, 'Female', 38, 78, 76],\n",
       "       [155, 'Female', 47, 78, 16],\n",
       "       [156, 'Female', 27, 78, 89],\n",
       "       [157, 'Male', 37, 78, 1],\n",
       "       [158, 'Female', 30, 78, 78],\n",
       "       [159, 'Male', 34, 78, 1],\n",
       "       [160, 'Female', 30, 78, 73],\n",
       "       [161, 'Female', 56, 79, 35],\n",
       "       [162, 'Female', 29, 79, 83],\n",
       "       [163, 'Male', 19, 81, 5],\n",
       "       [164, 'Female', 31, 81, 93],\n",
       "       [165, 'Male', 50, 85, 26],\n",
       "       [166, 'Female', 36, 85, 75],\n",
       "       [167, 'Male', 42, 86, 20],\n",
       "       [168, 'Female', 33, 86, 95],\n",
       "       [169, 'Female', 36, 87, 27],\n",
       "       [170, 'Male', 32, 87, 63],\n",
       "       [171, 'Male', 40, 87, 13],\n",
       "       [172, 'Male', 28, 87, 75],\n",
       "       [173, 'Male', 36, 87, 10],\n",
       "       [174, 'Male', 36, 87, 92],\n",
       "       [175, 'Female', 52, 88, 13],\n",
       "       [176, 'Female', 30, 88, 86],\n",
       "       [177, 'Male', 58, 88, 15],\n",
       "       [178, 'Male', 27, 88, 69],\n",
       "       [179, 'Male', 59, 93, 14],\n",
       "       [180, 'Male', 35, 93, 90],\n",
       "       [181, 'Female', 37, 97, 32],\n",
       "       [182, 'Female', 32, 97, 86],\n",
       "       [183, 'Male', 46, 98, 15],\n",
       "       [184, 'Female', 29, 98, 88],\n",
       "       [185, 'Female', 41, 99, 39],\n",
       "       [186, 'Male', 30, 99, 97],\n",
       "       [187, 'Female', 54, 101, 24],\n",
       "       [188, 'Male', 28, 101, 68],\n",
       "       [189, 'Female', 41, 103, 17],\n",
       "       [190, 'Female', 36, 103, 85],\n",
       "       [191, 'Female', 34, 103, 23],\n",
       "       [192, 'Female', 32, 103, 69],\n",
       "       [193, 'Male', 33, 113, 8],\n",
       "       [194, 'Female', 38, 113, 91],\n",
       "       [195, 'Female', 47, 120, 16],\n",
       "       [196, 'Female', 35, 120, 79],\n",
       "       [197, 'Female', 45, 126, 28],\n",
       "       [198, 'Male', 32, 126, 74],\n",
       "       [199, 'Male', 32, 137, 18],\n",
       "       [200, 'Male', 30, 137, 83]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb1bf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sebelum dinormalisasi :\n",
      "  Customer ID  Gender Age Income Spending Score\n",
      "0           1    Male  19     15             39\n",
      "1           2    Male  21     15             81\n",
      "2           3  Female  20     16              6\n",
      "3           4  Female  23     16             77\n",
      "4           5  Female  31     17             40\n",
      "5           6  Female  22     17             76\n",
      "6           7  Female  35     18              6\n",
      "7           8  Female  23     18             94\n",
      "8           9    Male  64     19              3\n",
      "9          10  Female  30     19             72\n",
      "dataset setelah dinormalisasi :\n",
      "        Age    Income  Spending Score Customer ID  Gender\n",
      "0  0.019231  0.000000        0.387755           1    Male\n",
      "1  0.057692  0.000000        0.816327           2    Male\n",
      "2  0.038462  0.008197        0.051020           3  Female\n",
      "3  0.096154  0.008197        0.775510           4  Female\n",
      "4  0.250000  0.016393        0.397959           5  Female\n",
      "5  0.076923  0.016393        0.765306           6  Female\n",
      "6  0.326923  0.024590        0.051020           7  Female\n",
      "7  0.096154  0.024590        0.948980           8  Female\n",
      "8  0.884615  0.032787        0.020408           9    Male\n",
      "9  0.230769  0.032787        0.724490          10  Female\n"
     ]
    }
   ],
   "source": [
    "X = array[:,2:5] #memisahkan fitur dari dataset. \n",
    "Y = array[:,0:1]  #memisahkan class dari dataset\n",
    "\n",
    "dataset=pd.DataFrame({\"Customer ID\":array[:,0],\"Gender\":array[:,1],\"Age\":array[:,2],\"Income\":array[:,3],\"Spending Score\":array[:,4]})\n",
    "print(\"dataset sebelum dinormalisasi :\")\n",
    "print(dataset.head(10))\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1)) #inisialisasi normalisasi MinMax\n",
    "data = min_max_scaler.fit_transform(X) #transformasi MinMax untuk fitur\n",
    "dataset = pd.DataFrame({\"Age\":data[:,0],\"Income\":data[:,1],\"Spending Score\":data[:,2],\"Customer ID\":array[:,0],\"Gender\":array[:,1]})\n",
    "\n",
    "print(\"dataset setelah dinormalisasi :\")\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24cf78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68eb0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e114e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029d8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8a163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfc808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be549942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c29696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043a39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc925d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d713b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7d6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df99d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58b591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
